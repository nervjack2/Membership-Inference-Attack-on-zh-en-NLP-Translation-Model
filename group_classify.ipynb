{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86. 爲此，糧農組織將考慮就如何設計1996年及其後年份的活動所提出的下述建議：</td>\n",
       "      <td>In this connection, FAO will consider the foll...</td>\n",
       "      <td>86. To this end, FAO will consider the followi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(a) 應當進一步開發變化矩陣系列的統計設計和分析系統：</td>\n",
       "      <td>(a) Statistical designs and analytical systems...</td>\n",
       "      <td>(a) The statistical design and analysis system...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>㈠ 利用輔助資料，例如，藉助美國諾阿的高級甚高分辨率輻射 計（一公里分辨率）以及各種數據庫（...</td>\n",
       "      <td>(i) To use the auxiliary information such as t...</td>\n",
       "      <td>(i) To use complementary information, such as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>㈡ 通過可減少森林面積變化數字差異的分層參數改進對變化的 估測，如人口統計學參數，經濟指示數...</td>\n",
       "      <td>(ii) To improve estimates for change by strati...</td>\n",
       "      <td>(ii) Improving the estimation of changes throu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(b) 應當進一步推動採用可靠的監測程序，如相互依賴的遙感分析，以獲得可協助決策的針對具體地...</td>\n",
       "      <td>(b) Sound monitoring procedures such as interd...</td>\n",
       "      <td>(b) The use of reliable monitoring procedures,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ori  \\\n",
       "0          86. 爲此，糧農組織將考慮就如何設計1996年及其後年份的活動所提出的下述建議：   \n",
       "1                       (a) 應當進一步開發變化矩陣系列的統計設計和分析系統：   \n",
       "2  ㈠ 利用輔助資料，例如，藉助美國諾阿的高級甚高分辨率輻射 計（一公里分辨率）以及各種數據庫（...   \n",
       "3  ㈡ 通過可減少森林面積變化數字差異的分層參數改進對變化的 估測，如人口統計學參數，經濟指示數...   \n",
       "4  (b) 應當進一步推動採用可靠的監測程序，如相互依賴的遙感分析，以獲得可協助決策的針對具體地...   \n",
       "\n",
       "                                                  gt  \\\n",
       "0  In this connection, FAO will consider the foll...   \n",
       "1  (a) Statistical designs and analytical systems...   \n",
       "2  (i) To use the auxiliary information such as t...   \n",
       "3  (ii) To improve estimates for change by strati...   \n",
       "4  (b) Sound monitoring procedures such as interd...   \n",
       "\n",
       "                                                pred  label  \n",
       "0  86. To this end, FAO will consider the followi...      0  \n",
       "1  (a) The statistical design and analysis system...      0  \n",
       "2  (i) To use complementary information, such as ...      0  \n",
       "3  (ii) Improving the estimation of changes throu...      0  \n",
       "4  (b) The use of reliable monitoring procedures,...      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "in_data = json.load(open('../Bob_translate_result/B_in_result.json'))\n",
    "out_data = json.load(open('../Bob_translate_result/B_out_result.json'))\n",
    "data = list(in_data.values()) + list(out_data.values())\n",
    "label = [0 for _ in range(len(list(in_data.values())))] + [1 for _ in range(len(list(out_data.values())))]\n",
    "data_dict = {'ori': [data[i][0] for i in range(len(data))], 'gt': [data[i][1] for i in range(len(data))], 'pred': [data[i][2] for i in range(len(data))], 'label': label}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>1-gram</th>\n",
       "      <th>2-gram</th>\n",
       "      <th>3-gram</th>\n",
       "      <th>4-gram</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86. 爲此，糧農組織將考慮就如何設計1996年及其後年份的活動所提出的下述建議：</td>\n",
       "      <td>In this connection, FAO will consider the foll...</td>\n",
       "      <td>86. To this end, FAO will consider the followi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.508918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(a) 應當進一步開發變化矩陣系列的統計設計和分析系統：</td>\n",
       "      <td>(a) Statistical designs and analytical systems...</td>\n",
       "      <td>(a) The statistical design and analysis system...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.182071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>㈠ 利用輔助資料，例如，藉助美國諾阿的高級甚高分辨率輻射 計（一公里分辨率）以及各種數據庫（...</td>\n",
       "      <td>(i) To use the auxiliary information such as t...</td>\n",
       "      <td>(i) To use complementary information, such as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.121242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>㈡ 通過可減少森林面積變化數字差異的分層參數改進對變化的 估測，如人口統計學參數，經濟指示數...</td>\n",
       "      <td>(ii) To improve estimates for change by strati...</td>\n",
       "      <td>(ii) Improving the estimation of changes throu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.156343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(b) 應當進一步推動採用可靠的監測程序，如相互依賴的遙感分析，以獲得可協助決策的針對具體地...</td>\n",
       "      <td>(b) Sound monitoring procedures such as interd...</td>\n",
       "      <td>(b) The use of reliable monitoring procedures,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ori  \\\n",
       "0          86. 爲此，糧農組織將考慮就如何設計1996年及其後年份的活動所提出的下述建議：   \n",
       "1                       (a) 應當進一步開發變化矩陣系列的統計設計和分析系統：   \n",
       "2  ㈠ 利用輔助資料，例如，藉助美國諾阿的高級甚高分辨率輻射 計（一公里分辨率）以及各種數據庫（...   \n",
       "3  ㈡ 通過可減少森林面積變化數字差異的分層參數改進對變化的 估測，如人口統計學參數，經濟指示數...   \n",
       "4  (b) 應當進一步推動採用可靠的監測程序，如相互依賴的遙感分析，以獲得可協助決策的針對具體地...   \n",
       "\n",
       "                                                  gt  \\\n",
       "0  In this connection, FAO will consider the foll...   \n",
       "1  (a) Statistical designs and analytical systems...   \n",
       "2  (i) To use the auxiliary information such as t...   \n",
       "3  (ii) To improve estimates for change by strati...   \n",
       "4  (b) Sound monitoring procedures such as interd...   \n",
       "\n",
       "                                                pred  label    1-gram  \\\n",
       "0  86. To this end, FAO will consider the followi...      0  0.684211   \n",
       "1  (a) The statistical design and analysis system...      0  0.500000   \n",
       "2  (i) To use complementary information, such as ...      0  0.465116   \n",
       "3  (ii) Improving the estimation of changes throu...      0  0.625000   \n",
       "4  (b) The use of reliable monitoring procedures,...      0  0.500000   \n",
       "\n",
       "     2-gram    3-gram    4-gram      bleu  \n",
       "0  0.555556  0.470588  0.375000  0.508918  \n",
       "1  0.200000  0.142857  0.076923  0.182071  \n",
       "2  0.190476  0.097561  0.025000  0.121242  \n",
       "3  0.260870  0.090909  0.047619  0.156343  \n",
       "4  0.200000  0.041667  0.000000  0.062779  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import modified_precision, sentence_bleu, SmoothingFunction\n",
    "\n",
    "def modified_n_gram_precisions(ref, hypo, n):\n",
    "    return float(modified_precision([ref.split()], hypo.split(), n))\n",
    "\n",
    "def bleu_score(ref, hypo):\n",
    "    chencherry = SmoothingFunction()\n",
    "    return sentence_bleu([ref.split()], hypo.split(), smoothing_function=chencherry.method1)\n",
    "\n",
    "df['1-gram'] = df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 1), axis=1)\n",
    "df['2-gram'] = df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 2), axis=1)\n",
    "df['3-gram'] = df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 3), axis=1)\n",
    "df['4-gram'] = df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 4), axis=1)\n",
    "df['bleu'] = df.apply(lambda r: bleu_score(r['gt'], r['pred']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def group_features(sample):\n",
    "    l = pd.cut(sample['bleu'], 100).value_counts().sort_index(axis=0).tolist()\n",
    "    a = sample['gt'].tolist()\n",
    "    ref = [[i.split()] for i in a]\n",
    "    a = sample['pred'].tolist()\n",
    "    hypo = [i.split() for i in a]\n",
    "    c_bleu = corpus_bleu(ref, hypo)\n",
    "    l.append(c_bleu)\n",
    "    return l\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "in_df, out_df = df[df['label'] == 0], df[df['label'] == 1]\n",
    "for i in range(3000):\n",
    "    in_sample, out_sample = in_df.sample(500), out_df.sample(500)\n",
    "    in_features, out_features = group_features(in_sample), group_features(out_sample)\n",
    "\n",
    "    X.append(in_features)\n",
    "    X.append(out_features)\n",
    "    y.append(0)\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=902022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Classifier on training set: 1.0\n",
      "The accuracy of Random Forest Classifier on testing set: 0.8341666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "print('The accuracy of Random Forest Classifier on training set:', rfc.score(X_train, y_train))\n",
    "print('The accuracy of Random Forest Classifier on testing set:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp2/b07902022/anaconda3/envs/SPML/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The accuracy of eXtreme Gradient Boosting Classifier on training set: 1.0\n",
      "The accuracy of eXtreme Gradient Boosting Classifier on testing set: 0.8391666666666666\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "xgbc.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on training set:', xgbc.score(X_train, y_train))\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of MLP Classifier on training set: 0.9860416666666667\n",
      "The accuracy of MLP Classifier on testing set: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp2/b07902022/anaconda3/envs/SPML/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('The accuracy of MLP Classifier on training set:', clf.score(X_train, y_train))\n",
    "print('The accuracy of MLP Classifier on testing set:', clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of KNN on testing set: 0.7877083333333333\n",
      "The accuracy of KNN on testing set: 0.6425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "print('The accuracy of KNN on testing set:', classifier.score(X_train, y_train))\n",
    "print('The accuracy of KNN on testing set:', classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>1-gram</th>\n",
       "      <th>2-gram</th>\n",
       "      <th>3-gram</th>\n",
       "      <th>4-gram</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第918(1994)號決議</td>\n",
       "      <td>RESOLUTION 918 (1994)</td>\n",
       "      <td>RESOLUTION 918 (1994) CONCERNING THE QUESTION ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994年5月17日安全理事會第3377次會議通過</td>\n",
       "      <td>Adopted by the Security Council at its 3377th ...</td>\n",
       "      <td>Adopted on 17 May 1994 by the Security Council...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>安全理事會，</td>\n",
       "      <td>The Security Council,</td>\n",
       "      <td>The Security Council,See Official Records of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>重申其以往關於盧旺達局勢的所有決議，特別是成立聯合國盧旺達援助團(聯盧援助團)的1993年1...</td>\n",
       "      <td>Reaffirming all its previous resolutions on th...</td>\n",
       "      <td>Reaffirming all its previous resolutions on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>回顧安理會主席以安理會名義在1994年4月7日發表的聲明(S/PRST/ 1994/16)和...</td>\n",
       "      <td>Recalling the statements made by the President...</td>\n",
       "      <td>Recalling the statements made by the President...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.701306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ori  \\\n",
       "0                                      第918(1994)號決議   \n",
       "1                          1994年5月17日安全理事會第3377次會議通過   \n",
       "2                                             安全理事會，   \n",
       "3  重申其以往關於盧旺達局勢的所有決議，特別是成立聯合國盧旺達援助團(聯盧援助團)的1993年1...   \n",
       "4  回顧安理會主席以安理會名義在1994年4月7日發表的聲明(S/PRST/ 1994/16)和...   \n",
       "\n",
       "                                                  gt  \\\n",
       "0                              RESOLUTION 918 (1994)   \n",
       "1  Adopted by the Security Council at its 3377th ...   \n",
       "2                              The Security Council,   \n",
       "3  Reaffirming all its previous resolutions on th...   \n",
       "4  Recalling the statements made by the President...   \n",
       "\n",
       "                                                pred  label    1-gram  \\\n",
       "0  RESOLUTION 918 (1994) CONCERNING THE QUESTION ...      0  0.187500   \n",
       "1  Adopted on 17 May 1994 by the Security Council...      0  0.764706   \n",
       "2  The Security Council,See Official Records of t...      0  0.117647   \n",
       "3  Reaffirming all its previous resolutions on th...      0  0.890909   \n",
       "4  Recalling the statements made by the President...      0  0.720000   \n",
       "\n",
       "     2-gram    3-gram    4-gram      bleu  \n",
       "0  0.133333  0.071429  0.000000  0.060879  \n",
       "1  0.687500  0.600000  0.500000  0.630191  \n",
       "2  0.062500  0.000000  0.000000  0.024325  \n",
       "3  0.722222  0.603774  0.500000  0.533743  \n",
       "4  0.708333  0.695652  0.681818  0.701306  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_in_data = json.load(open('../Bob_translate_result/A_in_result.json'))\n",
    "a_out_data = json.load(open('../Bob_translate_result/A_out_result.json'))\n",
    "a_data = list(a_in_data.values()) + list(a_out_data.values())\n",
    "a_label = [0 for _ in range(len(list(a_in_data.values())))] + [1 for _ in range(len(list(a_out_data.values())))]\n",
    "a_data_dict = {'ori': [a_data[i][0] for i in range(len(a_data))], 'gt': [a_data[i][1] for i in range(len(a_data))], 'pred': [a_data[i][2] for i in range(len(a_data))], 'label': a_label}\n",
    "a_df = pd.DataFrame(a_data_dict)\n",
    "a_df.head()\n",
    "\n",
    "a_df['1-gram'] = a_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 1), axis=1)\n",
    "a_df['2-gram'] = a_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 2), axis=1)\n",
    "a_df['3-gram'] = a_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 3), axis=1)\n",
    "a_df['4-gram'] = a_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 4), axis=1)\n",
    "a_df['bleu'] = a_df.apply(lambda r: bleu_score(r['gt'], r['pred']), axis=1)\n",
    "a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Classifier on Alice set: 0.5\n",
      "The accuracy of eXtreme Gradient Boosting Classifier on Alice set: 0.5\n",
      "The accuracy of MLP Classifier on Alice set: 0.488\n",
      "The accuracy of KNN on Alice set: 0.506\n"
     ]
    }
   ],
   "source": [
    "a_X, a_y = [], []\n",
    "\n",
    "a_in_df, a_out_df = a_df[a_df['label'] == 0], a_df[a_df['label'] == 1]\n",
    "for i in range(250):\n",
    "    in_sample, out_sample = a_in_df.sample(500), a_out_df.sample(500)\n",
    "    in_features, out_features = group_features(in_sample), group_features(out_sample)\n",
    "\n",
    "    a_X.append(in_features)\n",
    "    a_X.append(out_features)\n",
    "    a_y.append(0)\n",
    "    a_y.append(1)\n",
    "print('The accuracy of Random Forest Classifier on Alice set:', rfc.score(a_X, a_y))\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on Alice set:', xgbc.score(a_X, a_y))\n",
    "print('The accuracy of MLP Classifier on Alice set:', clf.score(a_X, a_y))\n",
    "print('The accuracy of KNN on Alice set:', classifier.score(a_X, a_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "      <th>1-gram</th>\n",
       "      <th>2-gram</th>\n",
       "      <th>3-gram</th>\n",
       "      <th>4-gram</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brion VIBBER</td>\n",
       "      <td>Brion VIBBER</td>\n",
       "      <td>Breon VIBBER Qualified by the Secretary-Genera...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Mountain</td>\n",
       "      <td>Mount'ain, please. No, no, you don't. You know...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>數學</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Mathematics (mathematicals).. 6 - 4 4 - 5 4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>目錄</td>\n",
       "      <td>Contents</td>\n",
       "      <td>Contents. 7 - 7 2 - 5 3 - 4 4 - 3 3 — 5 4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>哲學</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Philosophy (Psythropology).. 6 - 4 4 3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ori            gt  \\\n",
       "0  Brion VIBBER  Brion VIBBER   \n",
       "1      Mountain      Mountain   \n",
       "2            數學   Mathematics   \n",
       "3            目錄      Contents   \n",
       "4            哲學    Philosophy   \n",
       "\n",
       "                                                pred  label    1-gram  2-gram  \\\n",
       "0  Breon VIBBER Qualified by the Secretary-Genera...      1  0.100000     0.0   \n",
       "1  Mount'ain, please. No, no, you don't. You know...      1  0.000000     0.0   \n",
       "2        Mathematics (mathematicals).. 6 - 4 4 - 5 4      1  0.111111     0.0   \n",
       "3          Contents. 7 - 7 2 - 5 3 - 4 4 - 3 3 — 5 4      1  0.000000     0.0   \n",
       "4             Philosophy (Psythropology).. 6 - 4 4 3      1  0.142857     0.0   \n",
       "\n",
       "   3-gram  4-gram      bleu  \n",
       "0     0.0     0.0  0.021105  \n",
       "1     0.0     0.0  0.000000  \n",
       "2     0.0     0.0  0.023980  \n",
       "3     0.0     0.0  0.000000  \n",
       "4     0.0     0.0  0.033032  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ood_data = json.load(open('../Bob_translate_result/A_ood_result.json'))\n",
    "ood_data = list(ood_data.values())\n",
    "ood_label = [1 for _ in range(len(ood_data))]\n",
    "ood_data_dict = {'ori': [ood_data[i][0] for i in range(len(ood_data))], 'gt': [ood_data[i][1] for i in range(len(ood_data))], 'pred': [ood_data[i][2] for i in range(len(ood_data))], 'label': ood_label}\n",
    "ood_df = pd.DataFrame(ood_data_dict)\n",
    "ood_df.head()\n",
    "\n",
    "ood_df['1-gram'] = ood_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 1), axis=1)\n",
    "ood_df['2-gram'] = ood_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 2), axis=1)\n",
    "ood_df['3-gram'] = ood_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 3), axis=1)\n",
    "ood_df['4-gram'] = ood_df.apply(lambda r: modified_n_gram_precisions(r['gt'], r['pred'], 4), axis=1)\n",
    "ood_df['bleu'] = ood_df.apply(lambda r: bleu_score(r['gt'], r['pred']), axis=1)\n",
    "ood_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Classifier on Alice set: 0.54\n",
      "The accuracy of eXtreme Gradient Boosting Classifier on Alice set: 1.0\n",
      "The accuracy of MLP Classifier on Alice set: 1.0\n",
      "The accuracy of KNN on Alice set: 1.0\n"
     ]
    }
   ],
   "source": [
    "ood_X, ood_y = [], []\n",
    "\n",
    "for i in range(250):\n",
    "    sample = ood_df.sample(500)\n",
    "    features = group_features(sample)\n",
    "\n",
    "    ood_X.append(features)\n",
    "    ood_y.append(1)\n",
    "print('The accuracy of Random Forest Classifier on Alice set:', rfc.score(ood_X, ood_y))\n",
    "print('The accuracy of eXtreme Gradient Boosting Classifier on Alice set:', xgbc.score(ood_X, ood_y))\n",
    "print('The accuracy of MLP Classifier on Alice set:', clf.score(ood_X, ood_y))\n",
    "print('The accuracy of KNN on Alice set:', classifier.score(ood_X, ood_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for i in range(6000):\n",
    "    sample = df.sample(500)\n",
    "    features = group_features(sample)\n",
    "    count = sample[sample['label'] == 1].shape[0]\n",
    "\n",
    "    X.append(features)\n",
    "    y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Regressor on training set: 0.8594344630948925\n",
      "The accuracy of Random Forest Regressor on testing set: -0.008732927806421653\n",
      "The accuracy of eXtreme Gradient Boosting Regressor on training set: 0.8635444055243859\n",
      "The accuracy of eXtreme Gradient Boosting Regressor on testing set: -0.17696602660158112\n",
      "The accuracy of MLP Regressor on training set: 0.02496164995828387\n",
      "The accuracy of MLP Regressor on testing set: -0.011530413005686801\n",
      "The accuracy of KNN on testing set: 0.192633972041637\n",
      "The accuracy of KNN on testing set: -0.1922302137942502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=902022)\n",
    "rfc = RandomForestRegressor()\n",
    "rfc.fit(X_train, y_train)\n",
    "print('The accuracy of Random Forest Regressor on training set:', rfc.score(X_train, y_train))\n",
    "print('The accuracy of Random Forest Regressor on testing set:', rfc.score(X_test, y_test))\n",
    "xgbc = XGBRegressor()\n",
    "xgbc.fit(X_train, y_train)\n",
    "print('The accuracy of eXtreme Gradient Boosting Regressor on training set:', xgbc.score(X_train, y_train))\n",
    "print('The accuracy of eXtreme Gradient Boosting Regressor on testing set:', xgbc.score(X_test, y_test))\n",
    "clf = MLPRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "print('The accuracy of MLP Regressor on training set:', clf.score(X_train, y_train))\n",
    "print('The accuracy of MLP Regressor on testing set:', clf.score(X_test, y_test))\n",
    "Regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "Regressor.fit(X_train, y_train)\n",
    "print('The accuracy of KNN on testing set:', Regressor.score(X_train, y_train))\n",
    "print('The accuracy of KNN on testing set:', Regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Regressor on Alice set: -0.02238206949363919\n",
      "The accuracy of eXtreme Gradient Boosting Regressor on Alice set: -0.2007272231121653\n",
      "The accuracy of MLP Regressor on Alice set: -0.012497173484122381\n",
      "The accuracy of KNN on Alice set: -0.16813393673784005\n"
     ]
    }
   ],
   "source": [
    "a_X, a_y = [], []\n",
    "\n",
    "for i in range(500):\n",
    "    sample = a_df.sample(500)\n",
    "    features = group_features(sample)\n",
    "    count = sample[sample['label'] == 1].shape[0]\n",
    "\n",
    "    a_X.append(features)\n",
    "    a_y.append(count)\n",
    "print('The accuracy of Random Forest Regressor on Alice set:', rfc.score(a_X, a_y))\n",
    "print('The accuracy of eXtreme Gradient Boosting Regressor on Alice set:', xgbc.score(a_X, a_y))\n",
    "print('The accuracy of MLP Regressor on Alice set:', clf.score(a_X, a_y))\n",
    "print('The accuracy of KNN on Alice set:', Regressor.score(a_X, a_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Regressor on Alice set: 0.0\n",
      "The accuracy of eXtreme Gradient Boosting Regressor on Alice set: 0.0\n",
      "The accuracy of MLP Regressor on Alice set: 0.0\n",
      "The accuracy of KNN on Alice set: 0.0\n"
     ]
    }
   ],
   "source": [
    "ood_X, ood_y = [], []\n",
    "\n",
    "for i in range(250):\n",
    "    sample = ood_df.sample(500)\n",
    "    features = group_features(sample)\n",
    "\n",
    "    ood_X.append(features)\n",
    "    ood_y.append(500)\n",
    "print('The accuracy of Random Forest Regressor on Alice set:', rfc.score(ood_X, ood_y))\n",
    "print('The accuracy of eXtreme Gradient Boosting Regressor on Alice set:', xgbc.score(ood_X, ood_y))\n",
    "print('The accuracy of MLP Regressor on Alice set:', clf.score(ood_X, ood_y))\n",
    "print('The accuracy of KNN on Alice set:', Regressor.score(ood_X, ood_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df78dd037d091cdcd4c8ab510adf52376e642a3603acfd5cd746c9c6ee216ddb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('SPML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
